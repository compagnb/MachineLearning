{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #import numpy library\n",
    "import pandas as pd #import pandas library\n",
    "import matplotlib.pyplot as plt #import matplot library\n",
    "%matplotlib inline\n",
    "import nltk.classify.util\n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138806</td>\n",
       "      <td>138807</td>\n",
       "      <td>B000E63LME</td>\n",
       "      <td>A1CQGW1AOD0LF2</td>\n",
       "      <td>Alena K. \"Alena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Not as pictured.</td>\n",
       "      <td>I was looking forward to try cranberry apple f...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>TY for everything.  The seeds arrived quickly,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>I've finally found the best cereal in the worl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>485307</td>\n",
       "      <td>485308</td>\n",
       "      <td>B001RVFERK</td>\n",
       "      <td>A25W349EE97NBK</td>\n",
       "      <td>Tangent4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>I wanted to love these...</td>\n",
       "      <td>I originally bought these chips because I'd he...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>Really excellent tea, flowers are visible in t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
       "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
       "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       2      2  1294185600   \n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "3                     1                       1      4  1248307200   \n",
       "4                     0                       0      5  1333238400   \n",
       "\n",
       "                     Summary  \\\n",
       "0           Not as pictured.   \n",
       "1                      seeds   \n",
       "2              I'm addicted!   \n",
       "3  I wanted to love these...   \n",
       "4    Excellent chamomile tea   \n",
       "\n",
       "                                                Text  helpScore helpful  \n",
       "0  I was looking forward to try cranberry apple f...        0.5   False  \n",
       "1  TY for everything.  The seeds arrived quickly,...        NaN   False  \n",
       "2  I've finally found the best cereal in the worl...        NaN   False  \n",
       "3  I originally bought these chips because I'd he...        1.0   False  \n",
       "4  Really excellent tea, flowers are visible in t...        NaN   False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon.csv')\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "max must be larger than min in range parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0a90e581b1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make a histogram of all the ratings in the average_rating column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"helpScore\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Show the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   2956\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m                       stacked=stacked, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1810\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1811\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1812\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6008\u001b[0m             \u001b[0;31m# this will automatically overwrite bins,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6009\u001b[0m             \u001b[0;31m# so that each histogram uses the same bins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6010\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhist_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6011\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# causes problems later if it's an int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6012\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmlast\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             raise AttributeError(\n\u001b[0;32m--> 176\u001b[0;31m                 'max must be larger than min in range parameter.')\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# Histogram is an integer or a float array depending on the weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: max must be larger than min in range parameter."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWrMyEtSY/8LkDqzw0fZnlYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10de68240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a histogram of all the ratings in the average_rating column.\n",
    "plt.hist(data[\"helpScore\"])\n",
    "\n",
    "# Show the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert summary NaNs into usable format\n",
    "data.Summary = data.Summary.fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "\n",
    "# Features pulled from review txt\n",
    "data['reviewLen'] = data['Text'].str.len() #captures the amount of strings present in the review (i.e. review length)\n",
    "data['hasEP'] = data['Text'].str.contains('!') #captures the presences of an exclaimation point\n",
    "\n",
    "# 1st Attempt to add punctuation \n",
    "data['hasSemi'] = data['Text'].str.contains(';') #captures the presences of a ;\n",
    "data['hasColon'] = data['Text'].str.contains(':') #captures the presences of a :\n",
    "data['hasAt'] = data['Text'].str.contains('@') #captures the presences of a @\n",
    "data['hasDolla'] = data['Text'].str.contains('$') #captures the presences of a $\n",
    "data['hasNumb'] = data['Text'].str.contains('#') #captures the presences of a #\n",
    "data['hasAnd'] = data['Text'].str.contains('&') #captures the presences of a &\n",
    "\n",
    "# 2nd Attempt adding punctuation that needs \\ before (error the first time)\n",
    "data['hasQuestion'] = data['Text'].str.contains('\\?') #captures the presences of a ?\n",
    "data['hasAsterick'] = data['Text'].str.contains('\\*') #captures the presences of a *\n",
    "data['hasFparenthesis'] = data['Text'].str.contains('\\(') #captures the presences of a (\n",
    "data['hasBparenthesis'] = data['Text'].str.contains('\\)') #captures the presences of a )\n",
    "\n",
    "# add counts for punctuation \n",
    "data['epCount'] = data['Text'].str.count('!')\n",
    "data['semiCount'] = data['Text'].str.count(':')\n",
    "data['atCount'] = data['Text'].str.count('@')\n",
    "data['dollaCount'] = data['Text'].str.count('$')\n",
    "data['numbCount'] = data['Text'].str.count('#')\n",
    "data['andCount'] = data['Text'].str.count('&')\n",
    "data['questionCount'] = data['Text'].str.count('\\?')\n",
    "data['asterickCount'] = data['Text'].str.count('\\*')\n",
    "data['fParenthesisCount'] = data['Text'].str.count('\\(')\n",
    "data['bParenthesisCount'] = data['Text'].str.count('\\)')\n",
    "\n",
    "# add punctuation count and ratio of punctuation to words -- thank you jon!\n",
    "data['punctuationCount'] = data['Text'].str.count('[.,!;:()/\\?-@#$&]') #captures total common punctuation count\n",
    "data['punctuationToWords'] = data['punctuationCount'] / data['reviewLen'] #captures ratio of punctuation to words\n",
    "\n",
    "# add certain words\n",
    "\n",
    "# find repeating reviews\n",
    "data['repeatTxt'] = data.duplicated('Text')\n",
    "\n",
    "# add vars from profile name \n",
    "data['nameNumb'] = data['ProfileName'].str.contains('#') #captures profile name with a number sign\n",
    "data['nameQuestion'] = data['ProfileName'].str.contains('\\?')#captures profile name with a question mark\n",
    "data['nameAsterick'] = data['ProfileName'].str.contains('\\*') #captures profile name with an asterick\n",
    "data['nameAnd'] = data['ProfileName'].str.contains('&') #captures the presences of a &\n",
    "data['nameSemi'] = data['ProfileName'].str.contains(';') #captures the presences of a ;\n",
    "data['nameColon'] = data['ProfileName'].str.contains(':') #captures the presences of a :\n",
    "data['nameAt'] = data['ProfileName'].str.contains('@') #captures the presences of a @\n",
    "data['nameDolla'] = data['ProfileName'].str.contains('$') #captures the presences of a $\n",
    "\n",
    "# finding repeating profile names \n",
    "data['repeatProfile'] = data.duplicated('ProfileName')\n",
    "\n",
    "# Features pulled from summary txt\n",
    "data['summaryLen'] = data['Summary'].str.len() #captures the amount of strings present in the review (i.e. review length)\n",
    "data['summaryEP'] = data['Summary'].str.contains('!') #captures the presences of an exclaimation point\n",
    "\n",
    "# 1st Attempt to add punctuation \n",
    "data['summarySemi'] = data['Summary'].str.contains(';') #captures the presences of a ;\n",
    "data['summaryColon'] = data['Summary'].str.contains(':') #captures the presences of a :\n",
    "data['summaryAt'] = data['Summary'].str.contains('@') #captures the presences of a @\n",
    "data['summaryDolla'] = data['Summary'].str.contains('$') #captures the presences of a $\n",
    "data['summaryNumb'] = data['Summary'].str.contains('#') #captures the presences of a #\n",
    "data['summaryAnd'] = data['Summary'].str.contains('&') #captures the presences of a &\n",
    "\n",
    "# 2nd Attempt adding punctuation that needs \\ before (error the first time)\n",
    "data['summaryQuestion'] = data['Summary'].str.contains('\\?') #captures the presences of a ?\n",
    "data['summaryAsterick'] = data['Summary'].str.contains('\\*') #captures the presences of a *\n",
    "data['summaryFparenthesis'] = data['Summary'].str.contains('\\(') #captures the presences of a (\n",
    "data['summaryBparenthesis'] = data['Summary'].str.contains('\\)') #captures the presences of a )\n",
    "\n",
    "# add counts for punctuation \n",
    "data['summaryEpCount'] = data['Summary'].str.count('!')\n",
    "data['summarySemiCount'] = data['Summary'].str.count(':')\n",
    "data['summaryAtCount'] = data['Summary'].str.count('@')\n",
    "data['summaryDollaCount'] = data['Summary'].str.count('$')\n",
    "data['summaryNumbCount'] = data['Summary'].str.count('#')\n",
    "data['summaryAndCount'] = data['Summary'].str.count('&')\n",
    "data['summaryQuestionCount'] = data['Summary'].str.count('\\?')\n",
    "data['summaryAsterickCount'] = data['Summary'].str.count('\\*')\n",
    "data['summaryFParenthesisCount'] = data['Summary'].str.count('\\(')\n",
    "data['summaryBParenthesisCount'] = data['Summary'].str.count('\\)')\n",
    "\n",
    "# add punctuation count and ratio of punctuation to words -- thank you jon!\n",
    "data['summaryPunctuationCount'] = data['Summary'].str.count('[.,!;:()/\\?-@#$&]') #captures total common punctuation count\n",
    "data['summaryPunctuationToWords'] = data['punctuationCount'] / data['summaryLen'] #captures ratio of punctuation to words\n",
    "\n",
    "# add certain words\n",
    "\n",
    "# find repeating reviews\n",
    "data['summaryRepeatTxt'] = data.duplicated('Summary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking values and making vectors\n",
    "XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "XreviewLen = data.iloc[:, 13].values.reshape(data.shape[0], 1)\n",
    "XhasEP = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "XhasSemi = data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "XhasColon = data.iloc[:, 16].values.reshape(data.shape[0], 1)\n",
    "hasAt = data.iloc[:, 17].values.reshape(data.shape[0], 1)\n",
    "hasDolla = data.iloc[:, 18].values.reshape(data.shape[0], 1)\n",
    "hasNumb = data.iloc[:, 19].values.reshape(data.shape[0], 1)\n",
    "hasAnd = data.iloc[:, 20].values.reshape(data.shape[0], 1)\n",
    "hasQuestion = data.iloc[:, 21].values.reshape(data.shape[0], 1)\n",
    "hasAsterick = data.iloc[:, 22].values.reshape(data.shape[0], 1)\n",
    "hasFparenthesis = data.iloc[:, 23].values.reshape(data.shape[0], 1)\n",
    "hasBparenthesis = data.iloc[:, 24].values.reshape(data.shape[0], 1)\n",
    "epCount = data.iloc[:, 25].values.reshape(data.shape[0], 1)\n",
    "semiCount = data.iloc[:, 26].values.reshape(data.shape[0], 1)\n",
    "atCount = data.iloc[:, 27].values.reshape(data.shape[0], 1)\n",
    "dollaCount = data.iloc[:, 28].values.reshape(data.shape[0], 1)\n",
    "numbCount = data.iloc[:, 29].values.reshape(data.shape[0], 1)\n",
    "andCount = data.iloc[:, 30].values.reshape(data.shape[0], 1)\n",
    "questionCount = data.iloc[:, 31].values.reshape(data.shape[0], 1)\n",
    "asterickCount = data.iloc[:, 32].values.reshape(data.shape[0], 1)\n",
    "fParenthesisCount = data.iloc[:, 33].values.reshape(data.shape[0], 1)\n",
    "bParenthesisCount = data.iloc[:, 34].values.reshape(data.shape[0], 1)\n",
    "punctuationCount = data.iloc[:, 35].values.reshape(data.shape[0], 1)\n",
    "punctuationToWords = data.iloc[:, 36].values.reshape(data.shape[0], 1)\n",
    "repeatTxt = data.iloc[:, 37].values.reshape(data.shape[0], 1)\n",
    "nameNumb = data.iloc[:, 38].values.reshape(data.shape[0], 1)\n",
    "nameQuestion = data.iloc[:, 39].values.reshape(data.shape[0], 1)\n",
    "nameAsterick = data.iloc[:, 40].values.reshape(data.shape[0], 1)\n",
    "nameAnd = data.iloc[:, 41].values.reshape(data.shape[0], 1)\n",
    "nameSemi = data.iloc[:, 42].values.reshape(data.shape[0], 1)\n",
    "nameColon = data.iloc[:, 43].values.reshape(data.shape[0], 1)\n",
    "nameAt = data.iloc[:, 44].values.reshape(data.shape[0], 1)\n",
    "nameDolla = data.iloc[:, 45].values.reshape(data.shape[0], 1)\n",
    "repeatProfile = data.iloc[:, 46].values.reshape(data.shape[0], 1)\n",
    "summaryLen = data.iloc[:, 47].values.reshape(data.shape[0], 1)\n",
    "summaryEP = data.iloc[:, 48].values.reshape(data.shape[0], 1)\n",
    "summarySemi = data.iloc[:, 49].values.reshape(data.shape[0], 1)\n",
    "summaryColon = data.iloc[:, 50].values.reshape(data.shape[0], 1)\n",
    "summaryAt = data.iloc[:, 51].values.reshape(data.shape[0], 1)\n",
    "summaryDolla = data.iloc[:, 52].values.reshape(data.shape[0], 1)\n",
    "summaryNumb = data.iloc[:, 53].values.reshape(data.shape[0], 1)\n",
    "summaryAnd = data.iloc[:, 54].values.reshape(data.shape[0], 1)\n",
    "summaryQuestion = data.iloc[:, 55].values.reshape(data.shape[0], 1)\n",
    "summaryAsterick = data.iloc[:, 56].values.reshape(data.shape[0], 1)\n",
    "summaryFparenthesis = data.iloc[:, 57].values.reshape(data.shape[0], 1)\n",
    "summaryBparenthesis = data.iloc[:, 58].values.reshape(data.shape[0], 1)\n",
    "summaryEpCount = data.iloc[:, 59].values.reshape(data.shape[0], 1)\n",
    "summarySemiCount = data.iloc[:, 60].values.reshape(data.shape[0], 1)\n",
    "summaryAtCount = data.iloc[:, 61].values.reshape(data.shape[0], 1)\n",
    "summaryDollaCount = data.iloc[:, 62].values.reshape(data.shape[0], 1)\n",
    "summaryNumbCount = data.iloc[:, 63].values.reshape(data.shape[0], 1)\n",
    "summaryAndCount = data.iloc[:, 64].values.reshape(data.shape[0], 1)\n",
    "summaryQuestionCount = data.iloc[:, 65].values.reshape(data.shape[0], 1)\n",
    "summaryAsterickCount = data.iloc[:, 66].values.reshape(data.shape[0], 1)\n",
    "summaryFParenthesisCount = data.iloc[:, 67].values.reshape(data.shape[0], 1)\n",
    "summaryBParenthesisCount = data.iloc[:, 68].values.reshape(data.shape[0], 1)\n",
    "summaryPunctuationCount = data.iloc[:, 69].values.reshape(data.shape[0], 1)\n",
    "summaryPunctuationToWords = data.iloc[:, 70].values.reshape(data.shape[0], 1)\n",
    "summaryRepeatTxt = data.iloc[:, 71].values.reshape(data.shape[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>...</th>\n",
       "      <th>summaryDollaCount</th>\n",
       "      <th>summaryNumbCount</th>\n",
       "      <th>summaryAndCount</th>\n",
       "      <th>summaryQuestionCount</th>\n",
       "      <th>summaryAsterickCount</th>\n",
       "      <th>summaryFParenthesisCount</th>\n",
       "      <th>summaryBParenthesisCount</th>\n",
       "      <th>summaryPunctuationCount</th>\n",
       "      <th>summaryPunctuationToWords</th>\n",
       "      <th>summaryRepeatTxt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138806</td>\n",
       "      <td>138807</td>\n",
       "      <td>B000E63LME</td>\n",
       "      <td>A1CQGW1AOD0LF2</td>\n",
       "      <td>Alena K. \"Alena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Not as pictured.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>485307</td>\n",
       "      <td>485308</td>\n",
       "      <td>B001RVFERK</td>\n",
       "      <td>A25W349EE97NBK</td>\n",
       "      <td>Tangent4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>I wanted to love these...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
       "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
       "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       2      2  1294185600   \n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "3                     1                       1      4  1248307200   \n",
       "4                     0                       0      5  1333238400   \n",
       "\n",
       "                     Summary       ...        summaryDollaCount  \\\n",
       "0           Not as pictured.       ...                        1   \n",
       "1                      seeds       ...                        1   \n",
       "2              I'm addicted!       ...                        1   \n",
       "3  I wanted to love these...       ...                        1   \n",
       "4    Excellent chamomile tea       ...                        1   \n",
       "\n",
       "   summaryNumbCount summaryAndCount  summaryQuestionCount  \\\n",
       "0                 0               0                     0   \n",
       "1                 0               0                     0   \n",
       "2                 0               0                     0   \n",
       "3                 0               0                     0   \n",
       "4                 0               0                     0   \n",
       "\n",
       "  summaryAsterickCount summaryFParenthesisCount summaryBParenthesisCount  \\\n",
       "0                    0                        0                        0   \n",
       "1                    0                        0                        0   \n",
       "2                    0                        0                        0   \n",
       "3                    0                        0                        0   \n",
       "4                    0                        0                        0   \n",
       "\n",
       "  summaryPunctuationCount summaryPunctuationToWords summaryRepeatTxt  \n",
       "0                       1                  0.125000            False  \n",
       "1                       0                  0.600000            False  \n",
       "2                       1                  1.076923            False  \n",
       "3                       3                  1.240000            False  \n",
       "4                       0                  0.260870            False  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Xtoadd = np.concatenate((XScore, \n",
    "                         XreviewLen, \n",
    "                         XhasEP, \n",
    "                         XhasSemi, \n",
    "                         XhasColon, \n",
    "                         hasAt, \n",
    "                         hasDolla, \n",
    "                         hasNumb, \n",
    "                         hasAnd, \n",
    "                         hasQuestion, \n",
    "                         hasAsterick, \n",
    "                         hasFparenthesis, \n",
    "                         hasBparenthesis, \n",
    "                         epCount, \n",
    "                         semiCount, \n",
    "                         atCount, \n",
    "                         dollaCount, \n",
    "                         numbCount, \n",
    "                         andCount, \n",
    "                         questionCount, \n",
    "                         asterickCount, \n",
    "                         fParenthesisCount, \n",
    "                         bParenthesisCount, \n",
    "                         punctuationCount, \n",
    "                         punctuationToWords, \n",
    "                         repeatTxt, \n",
    "                         nameNumb, \n",
    "                         nameQuestion, \n",
    "                         nameAsterick, \n",
    "                         nameAnd, \n",
    "                         nameSemi, \n",
    "                         nameColon, \n",
    "                         nameAt, \n",
    "                         nameDolla, \n",
    "                         repeatProfile, \n",
    "                         summaryLen, \n",
    "                         summaryEP, \n",
    "                         summarySemi, \n",
    "                         summaryColon, \n",
    "                         summaryAt, \n",
    "                         summaryDolla, \n",
    "                         summaryNumb, \n",
    "                         summaryAnd, \n",
    "                         summaryQuestion, \n",
    "                         summaryAsterick, \n",
    "                         summaryFparenthesis, \n",
    "                         summaryBparenthesis, \n",
    "                         summaryEpCount, \n",
    "                         summarySemiCount, \n",
    "                         summaryAtCount, \n",
    "                         summaryDollaCount, \n",
    "                         summaryNumbCount, \n",
    "                         summaryAndCount, \n",
    "                         summaryQuestionCount, \n",
    "                         summaryAsterickCount, \n",
    "                         summaryFParenthesisCount, \n",
    "                         summaryBParenthesisCount, \n",
    "                         summaryPunctuationCount, \n",
    "                         summaryPunctuationToWords, \n",
    "                         summaryRepeatTxt), axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "def print_results():\n",
    "    print('Error rate on training set: ')\n",
    "    print((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('Accuracy rate on training set: ')\n",
    "    print(1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('True positive rate on training tet:')\n",
    "    print(((y_train==True) & (y_pred==True)).sum() / y_train.sum())\n",
    "    print('**************')\n",
    "    print('Error rate on test set: ')\n",
    "    print((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('Accuracy rate on test set: ')\n",
    "    print(1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('True positive rate on test set')\n",
    "    print(((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    print('True negative rate on test set')\n",
    "    print(((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # vectorize Bag of Words from review text; as sparse matrix\n",
    "# from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "# X = hv.transform(data.Text)\n",
    "\n",
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "X = hv.transform(data.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9f29423803f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mXtoaddSparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtoadd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mXfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtoaddSparse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     67\u001b[0m                         self.format)\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Read matrix dimensions given, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'to'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             coo_tocsr(M, N, self.nnz,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([X, XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 131072)\n"
     ]
    }
   ],
   "source": [
    "# size of feature set\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = data.iloc[:, 12].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_results() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3d751ade057c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: print_results() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_results() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cc0513bbb411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: print_results() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_results() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-996e532a4582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Naive Bayes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: print_results() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "print_results() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ed7009f40e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Perceptron'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: print_results() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
