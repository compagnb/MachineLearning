{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np #import numpy library\n",
    "import pandas as pd #import pandas library\n",
    "import matplotlib.pyplot as plt #import matplot library\n",
    "%matplotlib inline\n",
    "#you can also just write \"pylab\"\n",
    "\n",
    "import nltk.classify.util\n",
    "from astropy.table import Table, Column\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138806</td>\n",
       "      <td>138807</td>\n",
       "      <td>B000E63LME</td>\n",
       "      <td>A1CQGW1AOD0LF2</td>\n",
       "      <td>Alena K. \"Alena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Not as pictured.</td>\n",
       "      <td>I was looking forward to try cranberry apple f...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>TY for everything.  The seeds arrived quickly,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>I've finally found the best cereal in the worl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>485307</td>\n",
       "      <td>485308</td>\n",
       "      <td>B001RVFERK</td>\n",
       "      <td>A25W349EE97NBK</td>\n",
       "      <td>Tangent4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>I wanted to love these...</td>\n",
       "      <td>I originally bought these chips because I'd he...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>Really excellent tea, flowers are visible in t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
       "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
       "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       2      2  1294185600   \n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "3                     1                       1      4  1248307200   \n",
       "4                     0                       0      5  1333238400   \n",
       "\n",
       "                     Summary  \\\n",
       "0           Not as pictured.   \n",
       "1                      seeds   \n",
       "2              I'm addicted!   \n",
       "3  I wanted to love these...   \n",
       "4    Excellent chamomile tea   \n",
       "\n",
       "                                                Text  helpScore helpful  \n",
       "0  I was looking forward to try cranberry apple f...        0.5   False  \n",
       "1  TY for everything.  The seeds arrived quickly,...        NaN   False  \n",
       "2  I've finally found the best cereal in the worl...        NaN   False  \n",
       "3  I originally bought these chips because I'd he...        1.0   False  \n",
       "4  Really excellent tea, flowers are visible in t...        NaN   False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon.csv') #attach Amazon data to a var called data\n",
    "print(data.shape) #print data rows and columns\n",
    "data.head(5) #limit data to 5 rows including a header row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#smData = data[0:1000] #make a variabe for data subset limited to first 1000 \n",
    "#smData.shape #show how many rows and columns we have\n",
    "#print(smData.shape) #print data rows and columns\n",
    "#smData.head(5) #limit data to 5 rows including a header row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>...</th>\n",
       "      <th>punctuationCount</th>\n",
       "      <th>punctuationToWords</th>\n",
       "      <th>nameLen</th>\n",
       "      <th>nameNum</th>\n",
       "      <th>nameNumCount</th>\n",
       "      <th>nameQUOTE</th>\n",
       "      <th>nameSPACE</th>\n",
       "      <th>repeatUser</th>\n",
       "      <th>repeatSum</th>\n",
       "      <th>repeatText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454990</th>\n",
       "      <td>320405</td>\n",
       "      <td>320406</td>\n",
       "      <td>B000E1HVR0</td>\n",
       "      <td>A3CO3BDS4PXKL5</td>\n",
       "      <td>E. Morris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1249171200</td>\n",
       "      <td>OMG... need I say more</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454991</th>\n",
       "      <td>104610</td>\n",
       "      <td>104611</td>\n",
       "      <td>B000KSTY86</td>\n",
       "      <td>A3DTJW2ZSDQZ86</td>\n",
       "      <td>M. B. Goetz</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1270080000</td>\n",
       "      <td>Great coffee - Great price</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.025105</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454992</th>\n",
       "      <td>282272</td>\n",
       "      <td>282273</td>\n",
       "      <td>B000FICDO8</td>\n",
       "      <td>A3B5OLV01PVP85</td>\n",
       "      <td>D. Patel \"SpeedReader\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1258675200</td>\n",
       "      <td>Great taste with little effort.</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.027826</td>\n",
       "      <td>22</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454993</th>\n",
       "      <td>419683</td>\n",
       "      <td>419684</td>\n",
       "      <td>B0029ZAOW8</td>\n",
       "      <td>A2HAVA4SPL9HSM</td>\n",
       "      <td>Larry A. Chrispyn \"PUBLISHED POET\"</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1329696000</td>\n",
       "      <td>PRICE  TOO  HIGH  NO  EFFECT</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454994</th>\n",
       "      <td>115270</td>\n",
       "      <td>115271</td>\n",
       "      <td>B003E50WMY</td>\n",
       "      <td>A37FP7HWWNTW57</td>\n",
       "      <td>Gary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1314921600</td>\n",
       "      <td>My Poinion.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454995</th>\n",
       "      <td>457613</td>\n",
       "      <td>457614</td>\n",
       "      <td>B008Z5L2MW</td>\n",
       "      <td>A2W7HYIQWAJ091</td>\n",
       "      <td>Bonnie Pierce \"TexasBonnieBelle\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349049600</td>\n",
       "      <td>Outstanding - what else?</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.024291</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454996</th>\n",
       "      <td>283509</td>\n",
       "      <td>283510</td>\n",
       "      <td>B0045Z4JAI</td>\n",
       "      <td>AZ3GK5ZX3SVKT</td>\n",
       "      <td>gsue</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1306195200</td>\n",
       "      <td>Too weak, not enough umph!</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454997</th>\n",
       "      <td>292569</td>\n",
       "      <td>292570</td>\n",
       "      <td>B001BM68S4</td>\n",
       "      <td>A359CZWDE8MPMF</td>\n",
       "      <td>LC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1314576000</td>\n",
       "      <td>Good Stuff</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454998</th>\n",
       "      <td>156159</td>\n",
       "      <td>156160</td>\n",
       "      <td>B002YLG5MA</td>\n",
       "      <td>A1V8J8FKBZW68K</td>\n",
       "      <td>Ansella Adams \"Valley Lady\"</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1275350400</td>\n",
       "      <td>Way to Start the Day!</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454999</th>\n",
       "      <td>119066</td>\n",
       "      <td>119067</td>\n",
       "      <td>B004IREFUM</td>\n",
       "      <td>A1MYYCC9BSYV5Y</td>\n",
       "      <td>Colorado Mom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Delicious</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      Id   ProductId          UserId  \\\n",
       "454990      320405  320406  B000E1HVR0  A3CO3BDS4PXKL5   \n",
       "454991      104610  104611  B000KSTY86  A3DTJW2ZSDQZ86   \n",
       "454992      282272  282273  B000FICDO8  A3B5OLV01PVP85   \n",
       "454993      419683  419684  B0029ZAOW8  A2HAVA4SPL9HSM   \n",
       "454994      115270  115271  B003E50WMY  A37FP7HWWNTW57   \n",
       "454995      457613  457614  B008Z5L2MW  A2W7HYIQWAJ091   \n",
       "454996      283509  283510  B0045Z4JAI   AZ3GK5ZX3SVKT   \n",
       "454997      292569  292570  B001BM68S4  A359CZWDE8MPMF   \n",
       "454998      156159  156160  B002YLG5MA  A1V8J8FKBZW68K   \n",
       "454999      119066  119067  B004IREFUM  A1MYYCC9BSYV5Y   \n",
       "\n",
       "                               ProfileName  HelpfulnessNumerator  \\\n",
       "454990                           E. Morris                     0   \n",
       "454991                         M. B. Goetz                    11   \n",
       "454992              D. Patel \"SpeedReader\"                     1   \n",
       "454993  Larry A. Chrispyn \"PUBLISHED POET\"                     0   \n",
       "454994                                Gary                     0   \n",
       "454995    Bonnie Pierce \"TexasBonnieBelle\"                     0   \n",
       "454996                                gsue                     2   \n",
       "454997                                  LC                     0   \n",
       "454998         Ansella Adams \"Valley Lady\"                     4   \n",
       "454999                        Colorado Mom                     0   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "454990                       0      5  1249171200   \n",
       "454991                      11      5  1270080000   \n",
       "454992                       1      5  1258675200   \n",
       "454993                       2      1  1329696000   \n",
       "454994                       0      5  1314921600   \n",
       "454995                       0      5  1349049600   \n",
       "454996                       2      2  1306195200   \n",
       "454997                       0      5  1314576000   \n",
       "454998                       4      5  1275350400   \n",
       "454999                       0      5  1338422400   \n",
       "\n",
       "                                Summary    ...     punctuationCount  \\\n",
       "454990           OMG... need I say more    ...                    9   \n",
       "454991       Great coffee - Great price    ...                    6   \n",
       "454992  Great taste with little effort.    ...                   16   \n",
       "454993     PRICE  TOO  HIGH  NO  EFFECT    ...                    7   \n",
       "454994                      My Poinion.    ...                    1   \n",
       "454995         Outstanding - what else?    ...                    6   \n",
       "454996       Too weak, not enough umph!    ...                    5   \n",
       "454997                       Good Stuff    ...                   15   \n",
       "454998            Way to Start the Day!    ...                    6   \n",
       "454999                        Delicious    ...                    5   \n",
       "\n",
       "        punctuationToWords nameLen  nameNum nameNumCount nameQUOTE nameSPACE  \\\n",
       "454990            0.016014       9    False            0     False      True   \n",
       "454991            0.025105      11    False            0     False      True   \n",
       "454992            0.027826      22    False            0      True      True   \n",
       "454993            0.030568      34    False            0      True      True   \n",
       "454994            0.006944       4    False            0     False     False   \n",
       "454995            0.024291      32    False            0      True      True   \n",
       "454996            0.024510       4    False            0     False     False   \n",
       "454997            0.053004       2    False            0     False     False   \n",
       "454998            0.022556      27    False            0      True      True   \n",
       "454999            0.018182      12    False            0     False      True   \n",
       "\n",
       "       repeatUser repeatSum repeatText  \n",
       "454990       True     False      False  \n",
       "454991       True     False      False  \n",
       "454992      False     False      False  \n",
       "454993       True      True       True  \n",
       "454994       True     False      False  \n",
       "454995       True     False      False  \n",
       "454996       True      True       True  \n",
       "454997       True      True      False  \n",
       "454998      False     False      False  \n",
       "454999       True      True       True  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "\n",
    "# Features pulled from review txt\n",
    "data['reviewLen'] = data['Text'].str.len() #captures the amount of strings present in the review (i.e. review length)\n",
    "data['hasEP'] = data['Text'].str.contains('!') #captures the presences of an exclaimation point\n",
    "\n",
    "# 1st Attempt to add punctuation \n",
    "data['hasSemi'] = data['Text'].str.contains(';') #captures the presences of a ;\n",
    "data['hasColon'] = data['Text'].str.contains(':') #captures the presences of a :\n",
    "data['hasAt'] = data['Text'].str.contains('@') #captures the presences of a @\n",
    "data['hasDolla'] = data['Text'].str.contains('$') #captures the presences of a $\n",
    "data['hasNumb'] = data['Text'].str.contains('#') #captures the presences of a #\n",
    "data['hasAnd'] = data['Text'].str.contains('&') #captures the presences of a &\n",
    "\n",
    "# 2nd Attempt adding punctuation that needs \\ before (error the first time)\n",
    "data['hasQuestion'] = data['Text'].str.contains('\\?') #captures the presences of a ?\n",
    "data['hasAsterick'] = data['Text'].str.contains('\\*') #captures the presences of a *\n",
    "data['hasFparenthesis'] = data['Text'].str.contains('\\(') #captures the presences of a (\n",
    "data['hasBparenthesis'] = data['Text'].str.contains('\\)') #captures the presences of a )\n",
    "\n",
    "# add counts for punctuation \n",
    "data['epCount'] = data['Text'].str.count('!')\n",
    "data['semiCount'] = data['Text'].str.count(':')\n",
    "data['atCount'] = data['Text'].str.count('@')\n",
    "data['dollaCount'] = data['Text'].str.count('$')\n",
    "data['numbCount'] = data['Text'].str.count('#')\n",
    "data['andCount'] = data['Text'].str.count('&')\n",
    "data['questionCount'] = data['Text'].str.count('\\?')\n",
    "data['asterickCount'] = data['Text'].str.count('\\*')\n",
    "data['fParenthesisCount'] = data['Text'].str.count('\\(')\n",
    "data['bParenthesisCount'] = data['Text'].str.count('\\)')\n",
    "\n",
    "# add punctuation count and ratio of punctuation to words -- thank you jon!\n",
    "data['punctuationCount'] = data['Text'].str.count('[.,!;:()/\\?-@#$&]') #captures total common punctuation count\n",
    "data['punctuationToWords'] = data['punctuationCount'] / data['reviewLen'] #captures ratio of punctuation to words\n",
    "\n",
    "# add certain words\n",
    "\n",
    "# features related to profile name \n",
    "data['nameLen'] = data['ProfileName'].str.len()\n",
    "data['nameNum'] = data['ProfileName'].str.contains('\\d')\n",
    "data['nameNumCount'] = data['ProfileName'].str.count('\\d')\n",
    "data['nameQUOTE'] = data['ProfileName'].str.contains('\"')\n",
    "data['nameSPACE'] = data['ProfileName'].str.contains(' ')\n",
    "\n",
    "# finding repeating names \n",
    "data['repeatUser'] = data.duplicated('ProfileName')\n",
    "data['repeatSum'] = data.duplicated('Summary')\n",
    "data['repeatText'] = data.duplicated('Text')\n",
    "\n",
    "# \n",
    "data.tail(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking values and making vectors\n",
    "XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "XreviewLen = data.iloc[:, 13].values.reshape(data.shape[0], 1)\n",
    "XhasEP = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "XhasSemi = data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "XhasColon = data.iloc[:, 16].values.reshape(data.shape[0], 1)\n",
    "hasAt = data.iloc[:, 17].values.reshape(data.shape[0], 1)\n",
    "hasDolla = data.iloc[:, 18].values.reshape(data.shape[0], 1)\n",
    "hasNumb = data.iloc[:, 19].values.reshape(data.shape[0], 1)\n",
    "hasAnd = data.iloc[:, 20].values.reshape(data.shape[0], 1)\n",
    "hasQuestion = data.iloc[:, 21].values.reshape(data.shape[0], 1)\n",
    "hasAsterick = data.iloc[:, 22].values.reshape(data.shape[0], 1)\n",
    "hasFparenthesis = data.iloc[:, 23].values.reshape(data.shape[0], 1)\n",
    "hasBparenthesis = data.iloc[:, 24].values.reshape(data.shape[0], 1)\n",
    "epCount = data.iloc[:, 25].values.reshape(data.shape[0], 1)\n",
    "semiCount = data.iloc[:, 26].values.reshape(data.shape[0], 1)\n",
    "atCount = data.iloc[:, 27].values.reshape(data.shape[0], 1)\n",
    "dollaCount = data.iloc[:, 28].values.reshape(data.shape[0], 1)\n",
    "numbCount = data.iloc[:, 29].values.reshape(data.shape[0], 1)\n",
    "andCount = data.iloc[:, 30].values.reshape(data.shape[0], 1)\n",
    "questionCount = data.iloc[:, 31].values.reshape(data.shape[0], 1)\n",
    "asterickCount = data.iloc[:, 32].values.reshape(data.shape[0], 1)\n",
    "fParenthesisCount = data.iloc[:, 33].values.reshape(data.shape[0], 1)\n",
    "bParenthesisCount = data.iloc[:, 34].values.reshape(data.shape[0], 1)\n",
    "punctuationCount = data.iloc[:, 35].values.reshape(data.shape[0], 1)\n",
    "punctuationToWords = data.iloc[:, 36].values.reshape(data.shape[0], 1)\n",
    "nameLen = data.iloc[:, 37].values.reshape(data.shape[0], 1)\n",
    "nameNum = data.iloc[:, 38].values.reshape(data.shape[0], 1)\n",
    "nameNumCount = data.iloc[:, 39].values.reshape(data.shape[0], 1)\n",
    "nameQUOTE = data.iloc[:, 40].values.reshape(data.shape[0], 1)\n",
    "namespace = data.iloc[:, 41].values.reshape(data.shape[0], 1)\n",
    "repeatUser = data.iloc[:, 42].values.reshape(data.shape[0], 1)\n",
    "repeatSum = data.iloc[:, 43].values.reshape(data.shape[0], 1)\n",
    "repeatText = data.iloc[:, 44].values.reshape(data.shape[0], 1)\n",
    "\n",
    "\n",
    "Xtoadd = np.concatenate((XScore, XreviewLen, XhasEP, XhasSemi, XhasColon, hasAt, hasDolla, hasNumb, hasAnd, hasQuestion, hasAsterick, hasFparenthesis, hasBparenthesis, epCount, semiCount, atCount, dollaCount, numbCount, andCount, questionCount, asterickCount, fParenthesisCount, bParenthesisCount, punctuationCount, punctuationToWords, nameLen, nameNum, nameNumCount, nameQUOTE, namespace, repeatUser, repeatSum, repeatText), axis=1)\n",
    "\n",
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "global SVMerror, SVMacc, SVMtp, SVMtn, LRerror, LRacc, LRtp, LRtn, NBerror, NBacc, NBtp, NBtn, Perror, Pacc, Ptp, Ptn\n",
    "\n",
    "\n",
    "\n",
    "def print_results(model):\n",
    "    #print('Error rate on training set: ')\n",
    "    erTRAIN = ((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('Accuracy rate on training set: ')\n",
    "    AccTRAIN = (1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    #print('True positive rate on training tet:')\n",
    "    TruPosTRAIN = ((y_train==True) & (y_pred==True)).sum() / y_train.sum()\n",
    "    #TruNegTEST = (((y_train==False) & (y_pred_train==False)).sum() / (y_train.shape[0] - y_train.sum()))\n",
    "    #print('**************')\n",
    "    #('Error rate on test set: ')\n",
    "    erTEST = ((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('Accuracy rate on test set: ')\n",
    "    AccTEST = (1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    #print('True positive rate on test set')\n",
    "    TruPosTEST = (((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    #print('True negative rate on test set')\n",
    "    TruNegTEST = (((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))\n",
    "    data_rows = [('Error Rate', erTRAIN, erTEST),\n",
    "                 ('Accuracy Rate', AccTRAIN, AccTEST),\n",
    "                 ('True Positives', TruPosTRAIN, TruPosTEST),\n",
    "                 ('True Negatives', '--', TruNegTEST)]\n",
    "    t = Table(rows=data_rows, names=(model, 'Training Set', 'Test Set'), meta={'name': model + ': Training and Test Set Results'})\n",
    "    print(t)\n",
    "    if model == 'SVM':\n",
    "        SVMerror = erTEST\n",
    "        SVMacc = AccTEST\n",
    "        SVMtp = TruPosTEST\n",
    "        SVMtn = TruNegTEST\n",
    "        return(SVMerror, SVMacc, SVMtp, SVMtn)\n",
    "    elif model == 'Logistic Regression':\n",
    "        LRerror = erTEST\n",
    "        LRacc = AccTEST\n",
    "        LRtp = TruPosTEST\n",
    "        LRtn = TruNegTEST\n",
    "        return(LRerror, LRacc, LRtp, LRtn)\n",
    "    elif model == 'Naive Bayes':\n",
    "        NBerror = erTEST\n",
    "        NBacc = AccTEST\n",
    "        NBtp = TruPosTEST\n",
    "        NBtn = TruNegTEST\n",
    "        return(NBerror, NBacc, NBtp, NBtn)\n",
    "    elif model == 'Perceptron':\n",
    "        Perror = erTEST\n",
    "        Pacc = AccTEST\n",
    "        Ptp = TruPosTEST\n",
    "        Ptn = TruNegTEST\n",
    "        return(Perror, Pacc, Ptp, Ptn)\n",
    "    print('done')\n",
    "      \n",
    "    #t.show_in_browser(jsviewer=True) \n",
    "    \n",
    "    \n",
    "def all_models_table():\n",
    "    all_rows = [('SVM', SVMerror, SVMacc, SVMtp, SVMtn),\n",
    "            ('Logistic Regression', LRerror, LRacc, LRtp, LRtn),\n",
    "            ('Naive Bayes', NBerror, NBacc, NBtp, NBtn),\n",
    "            ('Perceptron', Perror, Pacc, Ptp, Ptn)]\n",
    "    tt = Table(rows=all_rows, names=('', 'Error Rate', 'Accuracy', 'True +', 'True -'), meta={'3/15/2016'})\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(min_df=1, ngram_range=(3,3))\n",
    "X = tv.fit_transform(data.Text)\n",
    "\n",
    "#if you restrict it to 2 to the power of 17 features is a few extra, way to restrict number of features created \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('O'),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9f29423803f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mXtoaddSparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtoadd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mXfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtoaddSparse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     67\u001b[0m                         self.format)\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Read matrix dimensions given, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'to'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m###################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             coo_tocsr(M, N, self.nnz,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)"
     ]
    }
   ],
   "source": [
    "# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([X, XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 10176762)\n"
     ]
    }
   ],
   "source": [
    "# size of feature set\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = data.iloc[:, 12].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SVM          Training Set      Test Set   \n",
      "-------------- ----------------- --------------\n",
      "    Error Rate 0.000806907378336 0.153003663004\n",
      " Accuracy Rate    0.999193092622 0.846996336996\n",
      "True Positives    0.993757534011 0.441890676526\n",
      "True Negatives                --  0.87904469022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.153003663003663,\n",
       " 0.84699633699633703,\n",
       " 0.44189067652643149,\n",
       " 0.87904469022001219)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "# will also go through each row as many times as you want it to - default is 5, making changes to weights, trying to\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression   Training Set      Test Set   \n",
      "------------------- ---------------- --------------\n",
      "         Error Rate 0.00121193092622 0.146637362637\n",
      "      Accuracy Rate   0.998788069074 0.853362637363\n",
      "     True Positives   0.995178233167  0.43669431398\n",
      "     True Negatives               -- 0.886325725534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14663736263736263,\n",
       " 0.8533626373626374,\n",
       " 0.43669431398021386,\n",
       " 0.88632572553421929)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Naive Bayes     Training Set       Test Set   \n",
      "-------------- ---------------- ---------------\n",
      "    Error Rate 0.00194662480377 0.0805054945055\n",
      " Accuracy Rate   0.998053375196  0.919494505495\n",
      "True Positives   0.999354227656  0.328969721195\n",
      "True Negatives               --   0.96621156902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.080505494505494504,\n",
       " 0.91949450549450551,\n",
       " 0.32896972119516338,\n",
       " 0.96621156901962957)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Perceptron     Training Set      Test Set   \n",
      "-------------- ---------------- --------------\n",
      "    Error Rate 0.00126530612245 0.153304029304\n",
      " Accuracy Rate   0.998734693878 0.846695970696\n",
      "True Positives   0.994403306354 0.444688717897\n",
      "True Negatives               --  0.87849920549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15330402930402931,\n",
       " 0.84669597069597069,\n",
       " 0.44468871789747177,\n",
       " 0.87849920548963178)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results('Perceptron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVMerror' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b01bf30f2d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_models_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-17176eafc2eb>\u001b[0m in \u001b[0;36mall_models_table\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mall_models_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     all_rows = [('SVM', SVMerror, SVMacc, SVMtp, SVMtn),\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLRtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'Naive Bayes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNBerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNBacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNBtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNBtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVMerror' is not defined"
     ]
    }
   ],
   "source": [
    "all_models_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
