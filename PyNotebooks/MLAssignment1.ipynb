{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/administrator/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/Users/administrator/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #import numpy library\n",
    "import pandas as pd #import pandas library\n",
    "import matplotlib.pyplot as plt #import matplot library\n",
    "%matplotlib inline\n",
    "#you can also just write \"pylab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138806</td>\n",
       "      <td>138807</td>\n",
       "      <td>B000E63LME</td>\n",
       "      <td>A1CQGW1AOD0LF2</td>\n",
       "      <td>Alena K. \"Alena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Not as pictured.</td>\n",
       "      <td>I was looking forward to try cranberry apple f...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>TY for everything.  The seeds arrived quickly,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>I've finally found the best cereal in the worl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>485307</td>\n",
       "      <td>485308</td>\n",
       "      <td>B001RVFERK</td>\n",
       "      <td>A25W349EE97NBK</td>\n",
       "      <td>Tangent4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>I wanted to love these...</td>\n",
       "      <td>I originally bought these chips because I'd he...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>Really excellent tea, flowers are visible in t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
       "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
       "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       2      2  1294185600   \n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "3                     1                       1      4  1248307200   \n",
       "4                     0                       0      5  1333238400   \n",
       "\n",
       "                     Summary  \\\n",
       "0           Not as pictured.   \n",
       "1                      seeds   \n",
       "2              I'm addicted!   \n",
       "3  I wanted to love these...   \n",
       "4    Excellent chamomile tea   \n",
       "\n",
       "                                                Text  helpScore helpful  \n",
       "0  I was looking forward to try cranberry apple f...        0.5   False  \n",
       "1  TY for everything.  The seeds arrived quickly,...        NaN   False  \n",
       "2  I've finally found the best cereal in the worl...        NaN   False  \n",
       "3  I originally bought these chips because I'd he...        1.0   False  \n",
       "4  Really excellent tea, flowers are visible in t...        NaN   False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Amazon.csv') #attach Amazon data to a var called data\n",
    "print(data.shape) #print data rows and columns\n",
    "data.head(5) #limit data to 5 rows including a header row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#smData = data[0:1000] #make a variabe for data subset limited to first 1000 \n",
    "#smData.shape #show how many rows and columns we have\n",
    "#print(smData.shape) #print data rows and columns\n",
    "#smData.head(5) #limit data to 5 rows including a header row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>...</th>\n",
       "      <th>hasQuestion</th>\n",
       "      <th>hasAsterick</th>\n",
       "      <th>hasFparenthesis</th>\n",
       "      <th>hasBparenthesis</th>\n",
       "      <th>hasNumb</th>\n",
       "      <th>punctCount</th>\n",
       "      <th>punctToWords</th>\n",
       "      <th>punctuationCount</th>\n",
       "      <th>punctuationToWords</th>\n",
       "      <th>hasAnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138806</td>\n",
       "      <td>138807</td>\n",
       "      <td>B000E63LME</td>\n",
       "      <td>A1CQGW1AOD0LF2</td>\n",
       "      <td>Alena K. \"Alena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Not as pictured.</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>14</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>485307</td>\n",
       "      <td>485308</td>\n",
       "      <td>B001RVFERK</td>\n",
       "      <td>A25W349EE97NBK</td>\n",
       "      <td>Tangent4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>I wanted to love these...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>0.028156</td>\n",
       "      <td>31</td>\n",
       "      <td>0.028156</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>6</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
       "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
       "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       2      2  1294185600   \n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "3                     1                       1      4  1248307200   \n",
       "4                     0                       0      5  1333238400   \n",
       "\n",
       "                     Summary  ...   hasQuestion  hasAsterick hasFparenthesis  \\\n",
       "0           Not as pictured.  ...         False        False           False   \n",
       "1                      seeds  ...         False        False           False   \n",
       "2              I'm addicted!  ...         False        False           False   \n",
       "3  I wanted to love these...  ...         False        False           False   \n",
       "4    Excellent chamomile tea  ...         False        False           False   \n",
       "\n",
       "   hasBparenthesis hasNumb punctCount punctToWords punctuationCount  \\\n",
       "0            False   False          2     0.009709                2   \n",
       "1            False   False          3     0.024000                3   \n",
       "2            False   False         14     0.020649               14   \n",
       "3            False   False         31     0.028156               31   \n",
       "4            False   False          6     0.029851                6   \n",
       "\n",
       "  punctuationToWords hasAnd  \n",
       "0           0.009709  False  \n",
       "1           0.024000  False  \n",
       "2           0.020649  False  \n",
       "3           0.028156  False  \n",
       "4           0.029851  False  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "\n",
    "# Features pulled from review txt\n",
    "data['reviewLen'] = data['Text'].str.len() #captures the amount of strings present in the review (i.e. review length)\n",
    "data['hasEP'] = data['Text'].str.contains('!') #captures the presences of an exclaimation point\n",
    "\n",
    "# 1st Attempt to add punctuation \n",
    "data['hasSemi'] = data['Text'].str.contains(';') #captures the presences of a ;\n",
    "data['hasColon'] = data['Text'].str.contains(':') #captures the presences of a :\n",
    "data['hasAt'] = data['Text'].str.contains('@') #captures the presences of a @\n",
    "data['hasDolla'] = data['Text'].str.contains('$') #captures the presences of a $\n",
    "data['hasNumb'] = data['Text'].str.contains('#') #captures the presences of a #\n",
    "data['hasAnd'] = data['Text'].str.contains('&') #captures the presences of a &\n",
    "\n",
    "# 2nd Attempt adding punctuation that needs \\ before (error the first time)\n",
    "data['hasQuestion'] = data['Text'].str.contains('\\?') #captures the presences of a ?\n",
    "data['hasAsterick'] = data['Text'].str.contains('\\*') #captures the presences of a *\n",
    "data['hasFparenthesis'] = data['Text'].str.contains('\\(') #captures the presences of a (\n",
    "data['hasBparenthesis'] = data['Text'].str.contains('\\)') #captures the presences of a )\n",
    "\n",
    "#add punctuation count and ratio of punctuation to words -- thank you jon!\n",
    "data['punctuationCount'] = data['Text'].str.count('[.,!;:()/\\?-@#$&]') #captures total common punctuation count\n",
    "data['punctuationToWords'] = data['punctuationCount'] / data['reviewLen'] #captures ratio of punctuation to words\n",
    "\n",
    "\n",
    "\n",
    "# Features pulled from user name\n",
    "\n",
    "\n",
    "# Taking values and making vectors\n",
    "XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "XreviewLen = data.iloc[:, 13].values.reshape(data.shape[0], 1)\n",
    "XhasEP = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "XhasSemi = data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "XhasColon = data.iloc[:, 16].values.reshape(data.shape[0], 1)\n",
    "hasAt = data.iloc[:, 17].values.reshape(data.shape[0], 1)\n",
    "hasDolla = data.iloc[:, 18].values.reshape(data.shape[0], 1)\n",
    "hasNumb = data.iloc[:, 19].values.reshape(data.shape[0], 1)\n",
    "hasAnd = data.iloc[:, 20].values.reshape(data.shape[0], 1)\n",
    "hasQuestion = data.iloc[:, 21].values.reshape(data.shape[0], 1)\n",
    "hasAsterick = data.iloc[:, 22].values.reshape(data.shape[0], 1)\n",
    "hasFparenthesis = data.iloc[:, 23].values.reshape(data.shape[0], 1)\n",
    "hasBparenthesis = data.iloc[:, 24].values.reshape(data.shape[0], 1)\n",
    "punctuationCount = data.iloc[:, 25].values.reshape(data.shape[0], 1)\n",
    "punctuationToWords = data.iloc[:, 26].values.reshape(data.shape[0], 1)\n",
    "\n",
    "\n",
    "Xtoadd = np.concatenate((XScore, XreviewLen), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "X = hv.transform(data.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([X, XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 131074)\n"
     ]
    }
   ],
   "source": [
    "# size of feature set\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = data.iloc[:, 12].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ded6678af496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_results' is not defined"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e7172caccc24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_results' is not defined"
     ]
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
